surveys$season[(surveys$yday >= 61 & surveys$yday < 153 & surveys$survey_year %in% c(2000, 2004, 2008, 2012, 2016, 2020))] <- "2_spring"
surveys$season[(surveys$yday >= 153 & surveys$yday < 245 & surveys$survey_year %in% c(2000, 2004, 2008, 2012, 2016, 2020))] <- "3_summer"
surveys$season[(surveys$yday >= 245 & surveys$yday < 336 & surveys$survey_year %in% c(2000, 2004, 2008, 2012, 2016, 2020))] <- "4_fall"
# modify the few exceptions
surveys$season[as.character(surveys$survey_id) %in% c(
10250, 3974, 3973, 3976, 3975, 5825, 5795 , 5824, 5798, 5826,
5797, 5796, 5823, 5812, 5821, 5822, 5808, 5809, 5811, 5810)] <- "1_winter"
# Important: 'survey_year' for December surveys should considered part of the winter season for the next year
# e.g. if a survey was on December 15th 2001, that was part of the Winter 2002 season
# subset these entries and add 1 to the survey year
surveys$survey_year[which(surveys$yday >= 335 & surveys$season == "1_winter")] <- surveys$survey_year[which(surveys$yday >= 335 & surveys$season == "1_winter")] + 1
surveys$season <- as.factor(surveys$season)
surveys %>% arrange(yday)
# Here we can see that there are no 'Ave67_mid' after January 2016 in this dataset,
# and then the 'Ave67_down' starts in April 2016
obs %>% filter(site_code %in% c("Ave67_dwn_B1", "Ave67_mid_B1")) %>%
group_by(survey_date) %>% slice(1) %>% arrange(survey_date)
# Rename the site codes, in both the bird data and survey metadata
obs$site_code[which(obs$site_code == "Ave67_mid_B1")] <- "Ave67_dwn_B1"
surveys$site_code[which(surveys$site_code == "Ave67_mid_B1")] <- "Ave67_dwn_B1"
# Out of the 8,760 site-dates, only 14 included multiple survey IDs, such as U13 on 6/6/2000
obs %>% group_by(survey_date, site_code, survey_id) %>% filter(row_number() ==1) %>% ungroup() %>%
count(survey_date, site_code) %>% filter(n >1)
msurvey.dates <- obs %>% group_by(survey_date, site_code, survey_id) %>% filter(row_number() ==1) %>% ungroup() %>%
count(survey_date, site_code) %>% filter(n >1) %>% pull(survey_date)
msurvey.sites <- obs %>% group_by(survey_date, site_code, survey_id) %>% filter(row_number() ==1) %>% ungroup() %>%
count(survey_date, site_code) %>% filter(n >1) %>% pull(site_code)
# these are all the observations from those 14 surveys.
# None of these observation notes give much indication as to why there are multiple surveys on the same day
obs %>%
filter(survey_date %in% msurvey.dates, site_code %in% msurvey.sites) %>%
arrange(survey_date, time_start, survey_id)
#arrange(desc(observation_notes))
# 6 of those 14 occasions were the same person on multiple survey IDs
obs %>% group_by(survey_date, site_code, survey_id, observer) %>% filter(row_number() ==1) %>% ungroup() %>%
count(survey_date, site_code, observer) %>% filter(n > 1)
# For most of the cases in which there are multiple survey IDs per day/site, there are different start times,
# indicating multiple 15-minute point counts were conducted (why is still not entirely clear)
# In which case, do we average across the counts for each species, standardizing per 15 minute survey?
# Or do we choose the max count of each species across the multiple surveys
# However, there were previously 4 cases in which the same 15-min point count appears to have been given multiple survey IDs
# e.g. EN-7B on 2004-11-04 has two different survey IDs (2480 and 2509) for seemingly the same 15-min pt count by the same observer
# obs %>% group_by(survey_date, site_code, survey_id, time_start, observer) %>%
#   filter(row_number() ==1) %>% ungroup()  %>%
#   count(site_code, survey_date, time_start, observer) %>% filter(n > 1) %>%
#   arrange(survey_date, site_code, time_start)
# same observer with multiple survey IDS
#   T-19	2000-10-17	09:10:00	BeRa	2
#   V-20	2003-10-06	07:55:00	SuWi	2
#   AC-16	2004-10-16	08:55:00	JiJo	2
#   EN-7B	2004-11-04	09:05:00	JiJo	2
# and one survey visit with multiple observers with the same start time (they counted the same birds)
# obs %>% group_by(survey_date, site_code, survey_id, time_start, observer) %>% filter(row_number() ==1) %>% ungroup()  %>%
# count(site_code, survey_date, time_start) %>% filter(n > 1) %>% arrange(survey_date, site_code, time_start)
#   T-19	2004-10-23	10:40:00	2
# check individual surveys
# same observer at two different times, indicating separate point count stations
# obs %>% filter(survey_date == "2000-06-06", site_code ==	"U-13") %>% arrange(time_start, code)  # remove 29 and 30 pilot surveys
# obs %>% filter(survey_date == "2003-10-16", site_code ==	"U-12") %>% arrange(code, time_start)  # one of the U-12 site IDs is incorrect
# obs %>% filter(survey_date == "2005-07-23", site_code ==	"U-12") %>% arrange(time_start, code)  # errors
# obs %>% filter(survey_date == "2005-07-15", site_code ==	"PN-2A") %>% arrange(time_start, code) # errors
# obs %>% filter(survey_date == "2016-02-03", site_code ==	"AD-10") %>% arrange(time_start, code) #
# obs %>% filter(survey_date == "2020-01-04", site_code ==	"PWRC") %>% arrange(time_start, code) # one of these is PWRA but cannot discern the correct fix
# Two survey IDs for two separate point counts (diff times and observers)
# obs %>% filter(survey_date == "2000-11-24", site_code ==	"M-16")     # irresolvable error
# obs %>% filter(survey_date == "2000-11-24", site_code ==	"N-12")     # irresolvable error
# obs %>% filter(survey_date == "2001-01-11", site_code ==	"EE-15A")   # irresolvable error
# obs %>% filter(survey_date == "2004-02-01", site_code ==	"X-18") %>% arrange(time_start, code)   # irresolvable error
# obs %>% filter(survey_date == "2004-02-01", site_code ==	"Y-19") %>% arrange(time_start, code)   # irresolvable error
# obs %>% filter(survey_date == "2004-02-06", site_code ==	"V-13") %>% arrange(time_start, code)   # irresolvable error
# obs %>% filter(survey_date == "2004-02-06", site_code ==	"V-14") %>% arrange(time_start, code)   # irresolvable error
# DUPLICATES:
# multiple survey IDs for the same start times and identical bird observations (same or different observers)
# In these cases, we can simply remove one of the survey IDs
# obs %>% filter(survey_date == "2000-10-17", site_code ==	"T-19")  # remove survey ID 170 or 172. 146 is a different start time
# obs %>% filter(survey_date == "2003-10-06", site_code ==	"V-20")   # remove ID 1996 or 1937
# obs %>% filter(survey_date == "2004-10-16", site_code ==	"AC-16") %>% arrange(time_start, code) # remove ID 2510 or 2507
# obs %>% filter(survey_date == "2004-10-23", site_code ==	"T-19") %>% arrange(time_start, code)  # remove ID 5938
# obs %>% filter(survey_date == "2004-11-04", site_code ==	"EN-7B") %>% arrange(time_start, code) # remove ID 2509
obs %>% filter(survey_id %in% c(
# These two surveys were the very first sampling of the project
# Not clear why there are two in one day. Perhaps it was a test run
29, 30,
# these five were duplicated, but those have been removed from the dataset already
172, 170,   # 172 has been removed
1996, 1937, # 1937 has been removed
2510, 2507, # 2507 has been removed
2519, 5938, # 5938 has been removed
2480, 2509  # 2509 has been removed
))  %>% arrange(survey_id)
obs <- obs %>% filter(!survey_id %in% c(
29, 30,
172, 1937, 2507, 5938, 2509
))
# before joining with the survey data, the observation data needs to be aggregated
# per the CAP bird survey protocol, birds are counted *as* they are observed in sequence
# consequently, many species were observed multiple times in a single survey (point in the point count)
# we want to sum these together, under the assumption that they were distinctly identified individuals
obs %>% arrange(survey_date, site_code, code, survey_id)
obs %>% count(survey_id, site_code, survey_date, code) %>% arrange(desc(n)) # how many separate entries were made for each species on each date
# First, summarize the amount surveyed per point count
obs.surveyID <- obs %>% #arrange(survey_id, code) %>%
group_by(survey_id, site_code, survey_date, observer, code, common_name) %>%
summarize(bird_count = sum(bird_count, na.rm = TRUE)) %>% ungroup()
obs.surveyID %>% arrange(survey_date, code, survey_id)
# obs %>% filter(seen == "FALSE") %>% filter(bird_count == 5) %>% arrange(heard)
# now counts have been summarized by survey ID
# but, we want counts summarized by survey *date*,
# and there were two surveys on dozens of survey dates
obs.surveyID %>% group_by(survey_id, survey_date, site_code) %>% filter(row_number()==1) %>% ungroup() %>%
count(site_code, survey_date) %>% arrange(desc(n))
# in the vast majority of cases, there was only one survey per day
# for a small number of cases, we have two surveys in one day
# these weren't conducted at the same time and/or by the same two people
# so we can't assume that counts from one survey ID are distinct individuals from the other survey ID
# and thus we get the maximum count for each species
# we've already gotten the total number of each species per survey ID, so we just need to get the max count per day
obs.date <- obs.surveyID %>% #arrange(survey_id, code) %>%
group_by(site_code, survey_date, code, common_name) %>%
# summarize(bird_count = max(bird_count, na.rm = TRUE)) %>%
arrange(desc(bird_count)) %>% slice(1) %>%  # this way will preserve the observer identity
ungroup()
obs.date %>% arrange(survey_date, code)
nrow(obs.surveyID); nrow(obs.date)
# the difference between these indicate that there were previously ~40 species observations recorded under multiple survey IDs on the same date
# but those have now been filtered out
# first, check the survey info by which the tables will be joined
obs.date %>% count(site_code, survey_date) %>% nrow()   # n = number of species in each
surveys %>% count(site_code, survey_date)  %>% nrow()
surveys %>% count(site_code, survey_date, observer) %>% filter(n > 1) # cases of multiple surveys by a single observer
length(unique(obs.date$survey_date)); length(unique(surveys$survey_date))
length(unique(obs.date$site_code)); length(unique(surveys$site_code))
length(unique(obs$survey_id)); length(unique(surveys$survey_id))
# there might be a few surveys not in the 'observations' dataset,
# presumably because no birds were detected during these surveys
surveys %>% filter(!survey_id %in% unique(obs$survey_id))
# obs %>% filter(!survey_id %in% unique(surveys$survey_id))
# try joining the observations and survey info
full_join(obs.date, surveys) %>% filter(!survey_id %in% unique(obs$survey_id))
# the join works, adding NAs to the surveys with no observations
# however, we will need to fill in those non-detections from the non-surveyed days,
# to do this, first duplicate each survey row for each species (nrow = n.surveys*n.spp = a lot of rows)
# second, fill in the counts with '0'
# list out all the species names
spp <- obs %>%
arrange(code) %>%
group_by(code, common_name) %>%
filter(row_number() == 1) %>%
dplyr::select(code, common_name) %>%
data.frame()
# spp
surveydays <- surveys %>% group_by(site_code, location_type, survey_date, yday, survey_year,
#observer,
season) %>%
summarize(survey_count = length(season)) %>%
arrange(survey_date, site_code) %>%
#arrange(desc(survey_count)) %>%
ungroup()
# add a new 'id column similar to survey_id' based on unique combinations of date and site
surveydays$site_date <- as.numeric(factor(paste0(surveydays$site_code, surveydays$survey_date)))
# a huge dataframe duplicating the survey info by the number of species
tmp <- data.frame(
#"survey_id" = rep(surveys$survey_id, each = nrow(spp)),
"site_date" = rep(surveydays$site_date, each = nrow(spp)),
"site_code" = rep(surveydays$site_code, each = nrow(spp)),
"location_type" = rep(surveydays$location_type, each = nrow(spp)),
"survey_date" = rep(surveydays$survey_date, each = nrow(spp)),
"yday" = rep(surveydays$yday, each = nrow(spp)),
"survey_year" = rep(surveydays$survey_year, each = nrow(spp)),
"season" = rep(surveydays$season, each = nrow(spp)),
#"time_start" = rep(surveys$time_start, each = nrow(spp)),
#"time_end" = rep(surveys$time_end, each = nrow(spp)),
# "observer" = rep(surveys$observer, each = nrow(spp)),
#"distance" = rep(surveys$distance, each = nrow(spp)),
"code" = rep(spp$code, length(surveydays$survey_date)),
"common_name" = rep(spp$common_name, length(surveydays$survey_date))
)
# create one big dataframe with non-detected species for each survey
obs.all <- full_join(obs.date, tmp)
obs.all[is.na(obs.all$bird_count) == TRUE,] %>% nrow()
obs.all[is.na(obs.all$bird_count) == FALSE,] %>% nrow() # filtered with base R
nrow(obs.all)
# for those sites that were surveyed but nothing was detected, set the count to 0
obs.all$bird_count[is.na(obs.all$bird_count) == TRUE] <- 0
# how many times each site was surveyed in a given season
# surveydays %>% count(survey_year, season, site_code) %>% arrange(site_code, survey_year)
# finally, add a column with 1/0 to represent whether the taxon was detected in that survey
obs.all$det <- obs.all$bird_count
obs.all$det[obs.all$bird_count > 0] <- 1
# and add a column with unique combination of years and season
obs.all$year_season <- paste(obs.all$survey_year, obs.all$season, sep = "_")
# and turn factors back into character vectors
obs.all$site_code <- as.character(obs.all$site_code)
obs.all$location_type <- as.character(obs.all$location_type)
obs.all$code <- as.character(obs.all$code)
obs.all$common_name <- as.character(obs.all$common_name)
obs.all$season <- as.character(obs.all$season)
obs.all$bird_count <- as.integer(obs.all$bird_count)
rm(tmp); gc()
colnames(obs.all)
# Firstly, we will exclude summer and fall surveys,
# as these seasons were not sampled after 2011 and 2004, respectively
# the last survey year for summer
obs.all %>% filter(season %in% c("3_summer")) %>% pull(survey_year) %>% range()
# the last survey year for fall
obs.all %>% filter(season %in% c("4_fall")) %>% pull(survey_year) %>% range()
# the number of sites that were sampled in those seasons,
# at least in years that they were sampled
obs.all %>% filter(season %in% c("3_summer", "4_fall")) %>%
pull(site_code) %>% unique() %>% length()
# Drop summer and fall. We could also do this later
#obs.all <- obs.all %>% filter(season %in% c("1_winter", "2_spring"))
# Secondly, following Allen et al 2019 and Albuquerque et al 2021, we can/should exclude 2003
# for its the anomalous lower sample size (due to no surveying of the riparian sites)
# however, we can also just filter this out later
#obs.all <- obs.all %>% filter(!survey_year %in% c(2003))
# Thirdly, we may end up limiting the analysis to just the sites surveyed for all 20 years
# i.e. the ESCA sites that were retained past 2016
obs.all %>% group_by(location_type) %>% summarize(year.start = min(survey_year), year.end = max(survey_year), n.site = length(unique(site_code)))
# Some ESCA sites (V14, W15) are part of the PASS sites after 2016,
# even though they say 'ESCA'
# Albuquerque et al. 2021 used 46 sites up until 2016,
# including some of the 'riparian' and/or NDV sites
obs.all %>% filter(!location_type %in% c("desert_fertilization", "PASS")) %>% nrow()
# the number of ESCA sites, which were the only ones sampled throughout the whole period
obs.all %>% filter(location_type %in% c("ESCA")) %>% pull(site_code) %>% unique() %>% length()
# number of sites surveyed in each year/season
obs.all %>%
group_by(site_code, survey_year, season, code)  %>%
filter(code == "ABTO") %>% summarize(bird_count = max(bird_count)) %>%
group_by(survey_year, season) %>% summarize(n_site = length(season))
obs.all %>% group_by(site_code) %>%
arrange(survey_date) %>% slice(1) %>% arrange(location_type, site_code)
obs.all %>% group_by(site_code) %>%
arrange(desc(survey_date)) %>% slice(1) %>% arrange(location_type, site_code)
# obs.all %>% filter(site_code == "U-21")
n.site <- obs.all$site_code %>% unique() %>% length()
n.year <- obs.all$survey_year %>% unique() %>% length()
n.season <- obs.all$season %>% as.character() %>% unique() %>% length()
n.spp <- obs.all$code %>% unique() %>% length()
n.site*n.year*n.season
surveydays %>% count(site_code, survey_year, season) %>% nrow()
# if all sites were surveyed in every season of every year, then there should be about three times more surveys
# because there were ~2-4 surveys per season
# however, most sites were not surveyed across the full study period
obs.all %>%
group_by(site_code, location_type, survey_year, season, year_season, code) %>%
filter(code == "ABTO") %>% arrange(observer, site_code, survey_year, season)
# number of survey days per site, per season
(n.survey <- obs.all %>%
group_by(site_code, location_type, survey_year, season, year_season, code) %>%
filter(code == "ABTO") %>%
summarize(n_survey = length(season)) %>% select(-code) %>% arrange(n_survey, survey_year))
(n.observers <- obs.all %>%
group_by(site_code, location_type, survey_year, season, year_season, code) %>%
filter(code == "ABTO") %>% summarize(n_observers = length(unique(observer))) %>% select(-code) #%>%
# arrange(n_observers, survey_year)
)
mean(n.observers$n_observers)
hist(n.observers$n_observers)
max(n.observers$n_observers)
min(n.observers$n_observers)
sd(n.observers$n_observers)
# tmp <- surveydays %>% group_by(site_code, survey_year, season) %>% dplyr::select(-c(yday, survey_date, site_date))# %>%
#   filter(row_number() == 1) %>% ungroup()
# tmp %>% count(site_code, survey_year, season) %>% arrange(desc(n))
#
# survey_counts <- data.frame(
#   "site_code" = rep(sort(levels(surveydays$site_code)), each = n.year*n.season),
#   "survey_year" = rep(rep(sort(unique(surveydays$survey_year)), each = length(unique(surveydays$season))), n.site),
#   "season" = as.factor(rep(rep(sort(levels(surveydays$season)), length(unique(surveydays$survey_year))), n.site))
# ) %>% left_join(tmp) #%>% count(site_code, survey_year, season) %>% arrange(desc(n))
# How many sites were surveyed fewer than three times during the seasons of this analysis?
n.survey %>%
filter(season %in% c("1_winter", "2_spring")) %>%
filter(location_type %in% c("ESCA", "riparian")) %>%
filter(survey_year <= 2016 & survey_year >= 2001 & survey_year != 2003) %>%
filter(n_survey < 3)
# What was the mean number of surveys across these sites/seasons?
n.survey %>%
filter(season %in% c("1_winter", "2_spring")) %>%
filter(location_type %in% c("ESCA", "riparian")) %>%
filter(survey_year <= 2016 & survey_year >= 2001 & survey_year != 2003) %>%
ungroup() %>%
# group_by(year_season) %>%
summarize(mean(n_survey), sd(n_survey))
# What was the mean number of surveys across these sites/seasons?
n.observers %>%
filter(season %in% c("1_winter", "2_spring")) %>%
filter(location_type %in% c("ESCA", "riparian")) %>%
filter(survey_year <= 2016 & survey_year >= 2001 & survey_year != 2003) %>%
ungroup() %>%
# group_by(year_season) %>%
summarize(mean(n_observers), sd(n_observers), min(n_observers), max(n_observers))
# first need to designate a number of sampling occasions
n.survey %>% filter(n_survey > 3)
# there are only 20 seasons in which a site was sampled more than 3 times (only 14 if you exclude summer and fall)
# so in many cases, we can likely just truncate the data at 3 surveys, but let's include five columns in that dimension for now
# # sites X # species X # time points (survey season, in order) x survey days
# OR
# number of sites times two (for each season) X # species X # years X survey days
# unique combinations of survey year and season
# y.count <- array(dim = c(n.site, length(unique(obs.all$year_season)), n.spp, 5))
to.keep.seasons <- c("1_winter", "2_spring") # keep just these two season in this
spp <- spp %>% arrange(code)  # make sure the species names are sorted as well
y.count <- array(dim = c(n.site, n.spp, max(n.survey$n_survey), n.year, length(to.keep.seasons)))
# y.count1 <- array(dim = c(n.site, n.year, n.spp, max(n.survey$n_survey)))
# y.count2 <- array(dim = c(n.site, n.year, n.spp, max(n.survey$n_survey)))
str(y.count)
# manually set parameters for testing
t <- 24; s <- 2; occ <- 5
str(y.count[,,occ,t,s])
# add names to the array dimensions
# the loop below needs to go through these in order
dimnames(y.count)[[1]] <- sort(unique(n.survey$site_code))
dimnames(y.count)[[2]] <- sort(spp$code)
dimnames(y.count)[[3]] <- paste("occ", 1:max(n.survey$n_survey), sep ="")
dimnames(y.count)[[4]] <- sort(unique(n.survey$survey_year))
dimnames(y.count)[[5]] <- sort(unique(to.keep.seasons))
Sys.time() # this should take a couple minutes
for(t in 1:dim(y.count)[4]){   # n.year
# print(sort(unique(n.survey$survey_year))[t])
for(s in 1:dim(y.count)[5]){  # length(to.keep.seasons)
for(occ in 1:max(n.survey$n_survey)){
tmp <- obs.all %>% select(site_code, code, survey_year, season, survey_date, season, bird_count) %>%
filter(season ==  sort(unique(to.keep.seasons))[s]) %>%  #  dimnames(y.count)[[3]][s]
# filter to the specific year, starting with the first when sorted numerically(/alphabetically)
filter(survey_year == sort(unique(n.survey$survey_year))[t]) %>%  # dimnames(y.count)[[2]][t]
arrange(survey_year)  %>% group_by(site_code, code) %>%
# select the bird count from the specific occasion
#(and use the .groups argument to get rid of the 'summarise()' message)
summarize(bird_count = bird_count[occ], .groups = 'drop') %>% arrange(site_code, code) %>%  # select the bird count from the specific occasion
pivot_wider(names_from = code, values_from = bird_count)
# there are number of sites that were not surveyed at all in this particular season.
# Add these on with all NA
sites.miss <- unique(n.survey$site_code[which(!n.survey$site_code %in% tmp$site_code)])
# add those onto the data
tmp[(nrow(tmp)+1):(nrow(tmp)+length(sites.miss)),]$site_code <- sites.miss
# arrange the data and add it to the array
if(ncol(tmp) > 1){  # only add if we have data from some sites in that sampling period
y.count[,,occ,t,s] <-  tmp %>% arrange(site_code) %>% ungroup() %>%
select(-site_code) %>% as.matrix()
}
}
}
}
Sys.time()
# to verify that everything worked examine a season's abundances for a single species
# there were a number of sites surveyed only 1 or 2 times in spring 2020, so this is a good one to check
# y.count[,
#         which(dimnames(y.count)[[2]] == "HOSP"),
#         ,
#         which(dimnames(y.count)[[4]] == "2020"),
#         which(dimnames(y.count)[[5]] == "2_spring")
#         ]
# obs.all %>% filter(code == "HOSP") %>% filter(survey_year == "2020") %>% filter(season == "2_spring") %>% arrange(site_code)
# we can also filter species, seasons, etc.
# e.g., for an analysis using ESCA and Riparian sites from 2001 to 2016
# to.keep.years <- seq(2000, 2016, 1)
# to.keep.seasons <-  c("1_winter", "2_spring") # this was already defined above
#
# to.keep.sites <- obs.all %>%
#   filter(survey_year %in% to.keep.years) %>%
#   filter(season %in% to.keep.seasons)  %>%
#   filter(location_type %in% c("ESCA", "riparian")) %>%
#   pull(site_code) %>% unique()
#
# to.keep.sites
# to.keep.seasons
# to.keep.years
#
# str(
#   y.count[which(dimnames(y.count)[[1]] %in% to.keep.sites),
#           ,
#           which(dimnames(y.count)[[4]] == "HOSP"),
#           which(dimnames(y.count)[[2]] %in% to.keep.years),
#           which(dimnames(y.count)[[3]] %in% to.keep.seasons)
#           ]
# )
# for occupancy modeling, we can reduce these to by-survey detections
y <- y.count
y[y > 1] <- 1
y[, which(dimnames(y.count)[[4]] == "HOSP")
,
,
which(dimnames(y.count)[[2]] == "2020"),
which(dimnames(y.count)[[3]] == "2_spring")
]  %>% str()
# ysum <- apply(y, MARGIN = c(1,2,3,4), FUN = function(x) sum(x, na.rm = TRUE))
# str(ysum)
# we may also need an array of number of surveys by site/season
#str(y[,,1,])
K1 <- y[,1,,,]   # pick the first species, since the survey count is the same for all species
K1[is.na(K1)== FALSE] <- 1
K <- apply(K1, MARGIN = c(1,3,4), FUN = function(x) sum(x, na.rm = TRUE))
# dimnames(K)[[2]] <- dimnames(y)[[2]]
# K$site_code <- rownames(K)
# K <- K %>% pivot_longer(!site_code, names_to = "year_season", values_to = "n_survey") %>%
#   left_join(n.survey) %>%
#   arrange(site_code, year_season)
# K$survey_year <- substr(K$year_season, start = 1, stop = 4)
# K$season <- substr(K$year_season, start = 6, stop = nchar(k$year_season))
str(K)
# we may also want to average counts across surveys
# if we want just the first three surveys, then do y.count[,,,,1:3], and then just divide by three
y.count.sum <- apply(y.count, MARGIN = c(1,2,4,5), FUN = function(x) sum(x, na.rm = TRUE))
# str(y.count.sum)
# y.count.sum[1:5, 2, 2,
#         99:101]
# K[1:5, 2, 2,
#         99:101]
# mean count of each bird species across the first three surveys
y.count.mean <- apply(y.count, MARGIN = c(1,2,4,5), FUN = function(x) mean(x, na.rm = TRUE))
y.count.mean[is.nan(y.count.mean)== TRUE] <- NA
str(y.count.mean)
# total abundance of birds at each site/year/season
abund.tot <- apply(y.count.mean, MARGIN = c(1,3,4), FUN = function(x) sum(x, na.rm = TRUE))
# if we're planning to use occupancy or n-mixture models, our approach here would need to be different
# but if we're not, we can looking for the minimum number of individuals at each site during each season,
# which would be the maximum observed in any given survey within that season
obs.seas <- obs.all %>%
group_by(code, common_name, site_code, location_type, survey_year, season) %>%
summarize(count_max = max(bird_count, na.rm = TRUE),   # max number of each species observed across surveys
count_sum = sum(bird_count),                 # sum of each species count across surveys (not unique individuals)
n_survey = length(bird_count),
det_survey = sum(det),  # number of surveys in which the species was detected
det = max(det),
# create a 'count_mean' that is an average abundance standardized by the number of surveys at that place and time period
count_mean = count_sum/n_survey           # mean number of each species counted across surveys
# we can also use the max count among surveys to represent each species' abundance
) %>% full_join(n.survey)
# Get 'total abundance', the number of birds of any species observed at each site x year x season
# Brown et al. 2022 measured total abundance "by adding the maximum number of birds observed at a site within a year for a given season."
# It's not entirely clear what that means, but it sounds like we could sum the mean counts across species
abundance.tot <- obs.seas %>%
group_by(site_code, survey_year, season) %>%
summarize(abundance_tot = sum(count_mean)) %>%
arrange(desc(abundance_tot))
abundance.tot
# combined total bird abundance and calculate relative abundance for each species
obs.seas <- full_join(obs.seas, abundance.tot) %>%
arrange(site_code, survey_year, season) %>%
mutate(abundance_rel = count_mean/abundance_tot,
p_lnp = abundance_rel*log(abundance_rel+0.000000000001))   # add a very small number so that the log function works
obs.seas %>% filter(abundance_rel > 0.4)
# number of sites by season and location type
(sitesbyseason <- obs.seas %>%
group_by(survey_year, season, location_type, code) %>%
filter(code == "ABTO") %>% summarize(n_site = length(season)) %>% select(-code))
# visualize how many sites were surveyed in each year
# https://community.rstudio.com/t/creating-a-stacked-barplot-or-histogram/114005
plot1 <- ggplot(data = sitesbyseason %>% filter(season == "1_winter"), aes(x = survey_year, y=n_site, fill = location_type)) +
theme_classic()  +
geom_col(color="white")+
scale_fill_brewer(palette = "Dark2", labels = c("DesFert", "ESCA", "NDV", "PASS", "Riparian", "SRBP")) +
coord_cartesian(xlim = c(2000, 2023), ylim = c(0, 70)) +
geom_text(aes(x = survey_year, y = n_site, label = n_site, group = location_type),
position = position_stack(vjust = 0.5), size = 2) +
labs(x = "Year", y = "# of Sites", fill = "Site Group") +
theme(axis.text.x = element_text(face = "bold"),
axis.text.y = element_text(face = "bold"),
legend.title = element_text(face = "bold"),
legend.text = element_text(size = 10),
#axis.ticks = element_blank(),
axis.title.x = element_text(face = "bold", size = 18),
axis.title.y = element_text(face = "bold", size = 18))
plot1
plot2 <- ggplot(data = sitesbyseason %>% filter(season == "2_spring"), aes(x = survey_year, y=n_site, fill = location_type)) +
theme_classic() +
geom_col(color="white")+
scale_fill_brewer(palette = "Dark2", labels = c("DesFert", "ESCA", "NDV", "PASS", "Riparian", "SRBP")) +
coord_cartesian(xlim = c(2000, 2023), ylim = c(0, 70)) +
geom_text(aes(x = survey_year, y = n_site, label = n_site, group = location_type),
position = position_stack(vjust = 0.5), size = 2) +
labs(x = "Year", y = "# of Sites", fill = "Site Group") +
theme(axis.text.x = element_text(face = "bold"),
axis.text.y = element_text(face = "bold"),
legend.title = element_text(face = "bold"),
legend.text = element_text(size = 10),
#axis.ticks = element_blank(),
axis.title.x = element_text(face = "bold", size = 18),
axis.title.y = element_text(face = "bold", size = 18))
plot2
# ggsave("./figures/trends/sitesbyseason_corebirds_1winter.png",
#        plot1,
#        width = 6,
#        height = 4,
#        units = "in",
#        dpi = 300)
#
# ggsave("./figures/trends/sitesbyseason_corebirds_2spring.png",
#        plot2,
#        width = 6,
#        height = 4,
#        units = "in",
#        dpi = 300)
# ggplot(data = sitesbyseason) +
#   theme_classic() +
#   geom_line(aes(x = survey_year, y = n_site, group = location_type, color = location_type))
saveRDS(y.count, "~/GitHub/caplter-dynamicbirds/data/bird_observations_countbysurvey.rds")
saveRDS(K, "~/GitHub/caplter-dynamicbirds/data/bird_observations_surveycount.rds")
# write.csv(K, "./bird_observations_surveycount.csv", row.names = FALSE)
# str(apply(y.count, MARGIN = c(1,2,3), FUN = 'sum', na.rm = TRUE))
write.csv(obs.seas, "~/GitHub/caplter-dynamicbirds/data/bird_observations_countmeanbyseason.csv", row.names = FALSE)
# write.csv(obs.all, "~/GitHub/caplter-dynamicbirds/data/spp/bird_observations_cleaned.csv", row.names = FALSE)
knitr::opts_chunk$set(
echo = FALSE,
warning = FALSE,
include = TRUE
)
rm(list = ls())
gc()
